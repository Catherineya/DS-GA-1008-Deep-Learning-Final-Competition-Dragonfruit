{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4e66cb-80f9-4ad2-bc72-02af1e5c8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import torch.optim as optim\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab0e60fe-58da-4e5a-99b0-71d4b592cdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Mismatched number of images and masks in /scratch/yg2709/CSCI-GA-2572-Deep-Learning-Final-Competition-Dragonfruit/dataset/val/video_01370\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, directory, normalize=False, data_name='custom'):\n",
    "        super().__init__()\n",
    "        self.data_name = data_name\n",
    "        self.normalize = normalize\n",
    "        self.image_mask_pairs = []\n",
    "\n",
    "        # 遍历所有文件夹，找到图像文件和相应的掩码文件\n",
    "        for folder in sorted(Path(directory).iterdir()):\n",
    "            if folder.is_dir():\n",
    "                imgs = list(sorted(folder.glob('*.png'), key=lambda x: int(x.stem.split('_')[-1])))  \n",
    "                mask_file = next(folder.glob('*.npy'), None) \n",
    "                \n",
    "                if mask_file and len(imgs) > 0:\n",
    "                    masks = np.load(mask_file)  \n",
    "                    if len(imgs) == len(masks):\n",
    "                        for img, mask in zip(imgs, masks):\n",
    "                            self.image_mask_pairs.append((img, mask))\n",
    "                    else:\n",
    "                        print(f\"Warning: Mismatched number of images and masks in {folder}\")\n",
    "\n",
    "        # 图像的预处理\n",
    "        self.transform_image = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # 这里可以添加更多的转换，例如图像增强等\n",
    "        ])\n",
    "\n",
    "        # 控制是否进行归一化\n",
    "        if normalize:\n",
    "            self.transform_mask = transforms.Compose([\n",
    "                transforms.ToTensor(),  # 这会转换为0-1范围的浮点数\n",
    "                # 这里可以添加特定于掩码的其他预处理步骤\n",
    "            ])\n",
    "        else:\n",
    "            # 如果不归一化，仅转换为Tensor\n",
    "            self.transform_mask = lambda x: torch.from_numpy(x).long() \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_mask_pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_file, mask_array = self.image_mask_pairs[index]\n",
    "        image = self.transform_image(Image.open(image_file).convert('RGB')) \n",
    "        mask = self.transform_mask(mask_array)\n",
    "        return image, mask\n",
    "\n",
    "train_data = CustomDataset('/scratch/yg2709/CSCI-GA-2572-Deep-Learning-Final-Competition-Dragonfruit/dataset/train', normalize=False)\n",
    "val_data = CustomDataset('/scratch/yg2709/CSCI-GA-2572-Deep-Learning-Final-Competition-Dragonfruit/dataset/val', normalize=False)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)\n",
    "val_loader = DataLoader(val_data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf12888-07e8-47ea-bfe1-e2dd3e6c9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    " \n",
    "# 在uent中卷积一般成对使用\n",
    "class DoubleConv(nn.Sequential):\n",
    "    # 输入通道数， 输出通道数， mid_channels为成对卷积中第一个卷积层的输出通道数\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        if mid_channels is None:\n",
    "            mid_channels = out_channels\n",
    "        super(DoubleConv, self).__init__(\n",
    "            # 3*3卷积，填充为1，卷积之后输入输出的特征图大小一致\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    " \n",
    "# 下采样\n",
    "class Down(nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__(\n",
    "            # 1.最大池化的窗口大小为2， 步长为2\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # 2.两个卷积\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    " \n",
    " \n",
    "# 上采样\n",
    "class Up(nn.Module):\n",
    "    # bilinear是否采用双线性插值\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "        if bilinear:\n",
    "            # 使用双线性插值上采样\n",
    "            # 上采样率为2，双线性插值模式\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            # 使用转置卷积上采样\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    " \n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.up(x1)\n",
    "        # [N, C, H, W]\n",
    "        # 上采样之后的特征图与要拼接的特征图，高度方向的差值\n",
    "        diff_y = x2.size()[2] - x1.size()[2]\n",
    "        # 上采样之后的特征图与要拼接的特征图，宽度方向的差值\n",
    "        diff_x = x2.size()[3] - x1.size()[3]\n",
    " \n",
    "        # padding_left, padding_right, padding_top, padding_bottom\n",
    "        # 1.填充差值\n",
    "        x1 = F.pad(x1, [diff_x // 2, diff_x - diff_x // 2,\n",
    "                        diff_y // 2, diff_y - diff_y // 2])\n",
    " \n",
    "        # 2.拼接\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        # 3.两个卷积\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    " \n",
    "# 最后的1*1输出卷积\n",
    "class OutConv(nn.Sequential):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(OutConv, self).__init__(\n",
    "            nn.Conv2d(in_channels, num_classes, kernel_size=1)\n",
    "        )\n",
    " \n",
    " \n",
    "# unet网络模型\n",
    "class UNet(nn.Module):\n",
    "    # 参数: 输入通道数， 分割任务个数， 是否使用双线插值， 网络中第一个卷积通道个数\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 3,\n",
    "                 num_classes: int = 49,\n",
    "                 bilinear: bool = True,\n",
    "                 base_c: int = 64):\n",
    "        super(UNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.bilinear = bilinear\n",
    " \n",
    "        self.in_conv = DoubleConv(in_channels, base_c)\n",
    "        # 下采样，参数:输入通道,输出通道\n",
    "        self.down1 = Down(base_c, base_c * 2)\n",
    "        self.down2 = Down(base_c * 2, base_c * 4)\n",
    "        self.down3 = Down(base_c * 4, base_c * 8)\n",
    "        # 如果采用双线插值上采样为 2，采用转置矩阵上采样为 1\n",
    "        factor = 2 if bilinear else 1\n",
    "        # 最后一个下采样，如果是双线插值则输出通道为512，否则为1024\n",
    "        self.down4 = Down(base_c * 8, base_c * 16 // factor)\n",
    "        # 上采样，参数:输入通道,输出通道\n",
    "        self.up1 = Up(base_c * 16, base_c * 8 // factor, bilinear)\n",
    "        self.up2 = Up(base_c * 8, base_c * 4 // factor, bilinear)\n",
    "        self.up3 = Up(base_c * 4, base_c * 2 // factor, bilinear)\n",
    "        self.up4 = Up(base_c * 2, base_c, bilinear)\n",
    "        # 最后的1*1输出卷积\n",
    "        self.out_conv = OutConv(base_c, num_classes)\n",
    " \n",
    "    # 正向传播过程\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        # 1. 定义最开始的两个卷积层\n",
    "        x1 = self.in_conv(x)\n",
    "        # 2. contracting path（收缩路径）\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        # 3. expanding path（扩展路径）\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        # 4. 最后1*1输出卷积\n",
    "        logits = self.out_conv(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3eaf6e-eb02-4b05-a2a7-cedfe718ad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [13:18<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.2737, Train IoU: 0.3630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [11:27<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Val Loss: 0.0294, Val IoU: 0.7133\n",
      "Best model saved with IoU: 0.7133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:49<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 0.0157, Train IoU: 0.8272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Val Loss: 0.0119, Val IoU: 0.8673\n",
      "Best model saved with IoU: 0.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 0.0087, Train IoU: 0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Val Loss: 0.0088, Val IoU: 0.8878\n",
      "Best model saved with IoU: 0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:49<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 0.0066, Train IoU: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Val Loss: 0.0060, Val IoU: 0.9215\n",
      "Best model saved with IoU: 0.9215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 0.0064, Train IoU: 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Val Loss: 0.0071, Val IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 0.0051, Train IoU: 0.9275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Val Loss: 0.0049, Val IoU: 0.9323\n",
      "Best model saved with IoU: 0.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 0.0044, Train IoU: 0.9368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Val Loss: 0.0053, Val IoU: 0.9277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 0.0048, Train IoU: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Val Loss: 0.0072, Val IoU: 0.9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 0.0044, Train IoU: 0.9366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:52<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Val Loss: 0.0044, Val IoU: 0.9410\n",
      "Best model saved with IoU: 0.9410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 0.0039, Train IoU: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:52<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Val Loss: 0.0223, Val IoU: 0.8384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 0.0043, Train IoU: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Val Loss: 0.0045, Val IoU: 0.9414\n",
      "Best model saved with IoU: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 0.0041, Train IoU: 0.9451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Val Loss: 0.0049, Val IoU: 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:53<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 0.0037, Train IoU: 0.9497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:55<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Val Loss: 0.0048, Val IoU: 0.9396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 0.0035, Train IoU: 0.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:55<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Val Loss: 0.0049, Val IoU: 0.9436\n",
      "Best model saved with IoU: 0.9436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:51<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 0.0033, Train IoU: 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:52<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Val Loss: 0.0039, Val IoU: 0.9519\n",
      "Best model saved with IoU: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:51<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 0.0037, Train IoU: 0.9508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Val Loss: 0.0045, Val IoU: 0.9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 0.0032, Train IoU: 0.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:52<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Val Loss: 0.0037, Val IoU: 0.9546\n",
      "Best model saved with IoU: 0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 688/688 [03:50<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 0.0034, Train IoU: 0.9566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 687/687 [01:51<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Val Loss: 0.0039, Val IoU: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 10/688 [00:03<04:11,  2.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 28\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = UNet() \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize and move the JaccardIndex metric to the appropriate device\n",
    "jaccard = torchmetrics.JaccardIndex(num_classes=49, task=\"multiclass\").to(device)\n",
    "\n",
    "num_epochs = 50\n",
    "best_iou = 0.0  # Initialize best IoU\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "    for images, masks in tqdm(train_loader):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        preds = preds.to(device)\n",
    "        train_iou += jaccard(preds, masks).item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_iou /= len(train_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in tqdm(val_loader):\n",
    "            val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            val_loss += criterion(val_outputs, val_masks).item()\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            val_preds = val_preds.to(device)\n",
    "            val_iou += jaccard(val_preds, val_masks).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_iou /= len(val_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}')\n",
    "\n",
    "    # Save the best model if the current IoU is greater than the best recorded IoU\n",
    "    if val_iou > best_iou:\n",
    "        best_iou = val_iou\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'Best model saved with IoU: {best_iou:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e6ad7-ba98-46f2-86a9-ea861227ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# 假设 model 是你的训练好的模型，loader 是你的数据加载器\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for images, true_masks in train_loader:  # 加载一批图像和真实标签\n",
    "        images = images.to(device)  # 确保数据在正确的设备上\n",
    "        outputs = model(images)  # 获取模型输出\n",
    "        predicted_masks = outputs.argmax(1)  # 获取预测的类别\n",
    "\n",
    "        # 将预测掩码和真实掩码的数据类型转换为uint8\n",
    "        predicted_masks = predicted_masks.byte().cpu().data\n",
    "        true_masks = true_masks.byte().cpu().data\n",
    "\n",
    "        # 将第一个图像转换为PIL图像以便可视化\n",
    "        image = to_pil_image(images[0].cpu().data)\n",
    "        predicted_mask = to_pil_image(predicted_masks[0])\n",
    "        true_mask = to_pil_image(true_masks[0])\n",
    "\n",
    "        # 绘制图像、预测和真实标签\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(predicted_mask)\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(true_mask)\n",
    "        plt.title('True Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        break  # 通常只查看一批中的第一个样本，所以在这里停止\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b6a6c-1346-4899-b8f0-81627e16b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# 假设 model 是你的训练好的模型，loader 是你的数据加载器\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for images, true_masks in val_loader:  # 加载一批图像和真实标签\n",
    "        images = images.to(device)  # 确保数据在正确的设备上\n",
    "        outputs = model(images)  # 获取模型输出\n",
    "        predicted_masks = outputs.argmax(1)  # 获取预测的类别\n",
    "\n",
    "        # 将预测掩码和真实掩码的数据类型转换为uint8\n",
    "        predicted_masks = predicted_masks.byte().cpu().data\n",
    "        true_masks = true_masks.byte().cpu().data\n",
    "\n",
    "        # 将第一个图像转换为PIL图像以便可视化\n",
    "        image = to_pil_image(images[0].cpu().data)\n",
    "        predicted_mask = to_pil_image(predicted_masks[0])\n",
    "        true_mask = to_pil_image(true_masks[0])\n",
    "\n",
    "        # 绘制图像、预测和真实标签\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title('Input Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(predicted_mask)\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(true_mask)\n",
    "        plt.title('True Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        break  # 通常只查看一批中的第一个样本，所以在这里停止\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1696fc-e2d8-495b-99e5-96d4fbe91854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
